\section{Linear Algebra Applications}

BLAS ... important building blocks ...
\todo{Write stuff}

\subsection{Sum of absolute values}
\label{sec:asum}
\autoref{eq:asum} shows the mathematical definition of the sum of absolute values (short \emph{asum}) for a vector $\vec{x}$ of length $n$ with elements $x_i$:
\begin{equation}
  asum\ \vec{x} = \sum_{i=0}^{n} | x_i |
  \label{eq:asum}
\end{equation}
For all elements of the vector the absolute values are added up to produce the final scalar result.

\subsubsection*{\SkelCL Implementation}
In the \SkelCL programming model we can express \emph{asum} using the \map and \reduce skeletons as follows:
\begin{align}
  asum\ \vec{x} &= reduce\ (+)\ 0\ \big(\ map\ (|\, .\, |)\ \vec{x}\ \big)\label{eq:asum:skelcl}\\
  \text{where:} \qquad | a | &=
    \left\{
      \begin{array}{r l}
      a & \text{if } a \geq 0\\
      -a & \text{if } a < 0
      \end{array}
    \right.\nonumber
\end{align}

The \map skeleton applies the $abs$ function to each element of the input vector before the \reduce skeleton is used to sum up the elements.

The implementation using the \SkelCL library is shown in \autoref{lst:skelcl:asum}.
In lines~\ref{lst:skelcl:asum:skeletons:start}--\ref{lst:skelcl:asum:skeletons:end} the customized skeletons are defined.
The \map skeleton in \autoref{eq:asum:skelcl} corresponds directly to lines~\ref{lst:skelcl:asum:skeletons:start} and~\ref{lst:skelcl:asum:abs} in \autoref{lst:skelcl:asum} where the $|\, .\, |$ function is represented using a \Cpp lambda expression.
Line~\ref{lst:skelcl:asum:skeletons:end} corresponds directly to the \reduce skeleton in \autoref{eq:asum:skelcl}.
By applying the skeletons to the input vector (line~\ref{lst:skelcl:asum:call}) the result is computed and accessed in line~\ref{lst:skelcl:asum:return}.
In the \SkelCL library implementation the \reduce skeleton returns a vector containing a single element.
The containers in the \SkelCL library are implemented as \emph{futures}~\cite{HewittBa1977,FriedmanWi1978}.
This allows the computation of all skeletons to be performed asynchronously, \ie, when executing a skeleton the computation is launched and the called function returns immediately.
When accessing values of the returned container, \eg, via the array subscript operator as shown in line~\ref{lst:skelcl:asum:return}, the call will block until the accessed value has been computed.

\begin{lstlisting}[%                                                             
caption={Implementation of the \emph{asum} application in \SkelCL},%
numbers=left,%
float=tb,
label={lst:skelcl:asum}]
float asum(const Vector<float>& x) {
  auto absAll = map($\label{lst:skelcl:asum:skeletons:start}$
      [](float a){ if (a >= 0) return a; else return -a; });$\label{lst:skelcl:asum:abs}$
  auto sumUp = reduce([](float a, float b){return a+b;}, 0);$\label{lst:skelcl:asum:skeletons:end}$
  auto result = sumUp( absAll( x ) );$\label{lst:skelcl:asum:call}$
  return result[0]; }$\label{lst:skelcl:asum:return}$
\end{lstlisting}

We compare this implementation against a native OpenCL implementation and an implementation using the CUBLAS library.

\subsubsection*{Programming effort}
\todo{...}

\subsubsection*{Performance experiments}
\todo{...}

As discussed in \autoref{chapter:skelcl} the \SkelCL library implementation generates one (or more) OpenCL kernel for each skeleton.
This procedure makes it difficult to \emph{merge} multiple OpenCL kernels into a single one, which would be required to achieve a competitive performance to the native OpenCL implementation.
In \autoref{ch:fifth}, we will discuss a novel compilation technique addressing this challenge.
This technique supports the generation of a single efficient OpenCL kernel, also for implementing applications like the \emph{asum} example.

\subsection{Dot product}
\label{sec:dot}
The computation of the dot product, \aka scalar product, is a common mathematical operation performed on two input vectors $\vec{x}$ and $\vec{y}$ of identical length $n$ as defined in \autoref{eq:dot_product}:
\begin{equation}
  dotProduct\ \vec{x}\ \vec{y} = \sum_{i=0}^{n} x_i \times y_i
  \label{eq:dot_product}
\end{equation}

\subsubsection*{\SkelCL Implementation}
In \SkelCL we can express $dotProduct$ using the \zip and \reduce skeletons as follows:
\begin{equation}
  dotProduct\ \vec{x}\ \vec{y} = reduce\ (+)\ 0\ \big(\ zip\ (\times)\ \vec{x}\ \vec{y}\ \big)
\end{equation}

The \zip skeleton performs the pairwise multiplication of the input vectors before the \reduce skeleton is used to sum up the intermediate results.

\autoref{lst:skelcl:dot} shows the implementation using the \SkelCL library.
The structure of the implementation is very similar to the \emph{asum} application discussed in \autoref{sec:asum}.
Here we use the \code{front} member function to access the first (and only) element of the computed result vector.

\begin{lstlisting}[%                                                             
caption={Implementation of the dot product application in \SkelCL},%
numbers=left,%
float=tb,
label={lst:skelcl:dot}]
float dotProduct(const Vector<float>& x,
                 const Vector<float>& y) {
  auto mult  = zip([](float x, float y){return x*y;});$\label{lst:skelcl:dot:skeletons:start}$
  auto sumUp = reduce([](float x, float y){return x+y;}, 0);$\label{lst:skelcl:dot:skeletons:end}$
  return sumUp( mult( x, y ) ).front(); }$\label{lst:skelcl:dot:call}$
\end{lstlisting}

\subsubsection*{Programming effort}
\todo{...}

\subsubsection*{Performance experiments}
\todo{...}

\input{Chapters/Chapter4/matrix_matrix_multiplication.tex}

