% Chapter 4: Application Studies
\chapter{Application Studies}
\label{chapter:skelcl-evaluation}
\addtocontents{lof}{\protect\vspace{\beforebibskip}}%
\addtocontents{lol}{\protect\vspace{\beforebibskip}}%

\lettrine[lines=3, loversize=0.1]{I}{n this chapter} we present various application studies evaluating the usefulness and performance of the abstractions introduced by the \SkelCL programming model which were presented in the previous chapter.
We start with a brief discussion of the metrics used to evaluate the \SkelCL programming model and discuss the experimental setup used throughout the chapter.
We will then look at applications from a wide range of domains ranging from simple benchmark applications like the computation of the Mandelbrot set, over linear algebra and image processing applications, to real-world applications in medical imaging, and physics.

For all source codes we only show the relevant code sections and omit implementation details like initializing \SkelCL. %, including the correct set of header files, and prefix all symbols defined within the \code{skelcl} namespace.

\input{Chapters/Chapter4/experimental_setup.tex}

\input{Chapters/Chapter4/mandelbrot.tex}

\input{Chapters/Chapter4/linear_algebra.tex}

\input{Chapters/Chapter4/matrix_matrix_multiplication.tex}

\input{Chapters/Chapter4/stencil.tex}

\input{Chapters/Chapter4/medical_imaging.tex}

\input{Chapters/Chapter4/fdtd.tex}

% TODO: Include Bio informatic
% \input{Chapters/Chapter4/bio_info.tex}

\section{Summary}

\autoref{fig:skelcl:eval:summary:loc} and \autoref{fig:skelcl:eval:summary:runtime} summaries the findings of this chapter.

\autoref{fig:skelcl:eval:summary:loc} shows the lines of code required for implementing five of the applications examples in \OpenCL (on the left) and \SkelCL (on the right).
We scaled all graphs relative to the lines of code required by the \OpenCL implementation.
The \SkelCL code is significant shorter in all cases, requiring less than 50\% of the lines of code of the \OpenCL-based implementation.
For the linear algebra application, matrix multiplication, and image processing application even less than 15\% of lines of code are required when using \SkelCL.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{Plots/summary/summary_loc.pdf}
    \caption{Relative lines of code for five application examples discussed in this chapter comparing \OpenCL code with \SkelCL code.}
    \label{fig:skelcl:eval:summary:loc}
\end{figure}

\autoref{fig:skelcl:eval:summary:runtime} shows the runtime results for six of the application examples presented in this chapter.
We compare the runtime of optimized \OpenCL implementations against \SkelCL-based implementations.
For all shown application examples -- except the dot product application -- we can see that \SkelCL is close to the performance of the \OpenCL implementations.
For most applications the runtime of the \SkelCL-based implementations are within 10\% of the \OpenCL implementations.
For the matrix multiplication \SkelCL is 33\% slower than the optimized \OpenCL implementation which only operates on squared matrices.
The dot product application is significantly slower, as \SkelCL generates two separate \OpenCL kernels instead of a single optimized kernel.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{Plots/summary/summary_runtime.pdf}
    \caption{Relative runtime for six application examples discussed in this chapter comparing \OpenCL-based implementations with \SkelCL-based implementations.}
    \label{fig:skelcl:eval:summary:runtime}
\end{figure}

\section{Conclusion}
In this chapter we have thoroughly evaluated the \SkelCL programming model and its \Cpp library implementation.
We have seen that \SkelCL successfully addresses the programmability challenge and indeed greatly simplifies \GPU programming as compared to \OpenCL. 
For all investigated benchmarks we could see a reduction in the amount of code written by the programmer of up to 9 times for some benchmarks.
The performance results show that \SkelCL is able to achieve runtime performance on par with native written \OpenCL code for most benchmarks.
For two benchmarks, \emph{asum} and dot product, \SkelCL performs bad compared to native written code as unnecessarily multiple \OpenCL kernels are generated and executed.
We will present a compilation technique which addresses this performance drawback in \autoref{part:codeGeneration} of this thesis.

For the \stencil skeleton we saw, that the two presented implementations have slightly different performance characteristics.
Their overall performance is comparable to native written stencil code.

For the \allpairs skeleton we saw, that the specialized implementation taking advantage of the regular \zip-\reduce patterns offers large performance benefits as compared to the generic implementation.
For matrix multiplication the specialized implementation performs close to an optimized \OpenCL implementation, but still about 30\% slower than the highly optimized \BLAS implementations.

\bigskip

In the next part of the thesis we introduce a novel compilation technique which addresses the performance portability challenge of generating high performing code from a single high-level presentation.

