\section{Rewrite Rules}
\label{section:rules}

This section introduces our set of rewrite rules that transform high-level expressions written using our algorithmic patterns into semantically equivalent expressions.
One goal of our approach is to keep each rule as simple as possible and only express one fundamental concept at a time.
For instance the vectorization rule, as we will see, is the only place where we express the vectorization concept.
This is different from most prior approaches that would produce a special vectorized version of different algorithmic patterns such as map or reduce.
The superiority of our approach lies in the power of composition;
many rules can be applied successively to produce expressions that compose hardware concepts or optimizations and that are provably correct by construction.

Similarly to our patterns, we distinguish between algorithmic and lowering rules.
Algorithmic rules produce derivations that represent the different algorithmic choices.
Our \OpenCL-specific rules map expressions to \OpenCL patterns.
Once the expression is in its lowest form, it is possible to produce \OpenCL code for each single pattern easily with our code generator as described in the following section.

\todo{Explain syntax used}

%\paragraph{Syntax and Rule Derivation}
%Some rules can only be activated if certain conditions are true.
%We use the syntax $[pre:post]$ to represent the pre and post conditions of a rule.
%The pre condition $pre$ corresponds to the list of conditions that must be true for the rule to be applied.
%The post condition $post$ is set for any function bound to the pattern.
%The $\overline{\rule[-.3\baselineskip]{0pt}{1.5ex}\hspace{1.5ex}}$, $\wedge$, and $\vee$ corresponds to the logical \emph{not}, \emph{and}, and \emph{or} operators respectively.

%We use leftmost derivation when applying the rules, which means that the leftmost non-terminal is always derived first.

\newenvironment{rerule}[1]%
{\begin{equation}\begin{array}{#1}\ignorespaces}%
{\end{array}\end{equation}%
\ignorespacesafterend}

\newenvironment{rerule*}[1]%
{\begin{equation*}\begin{array}{#1}\ignorespaces}%
{\end{array}\end{equation*}%
\ignorespacesafterend}



\subsection{Algorithmic Rules}
\label{section:rules:algo}

Each algorithmic rule formulates a true statement of the relationship of multiple algorithmic patterns.
Applying the rule allows to rewrite an expression and, by doing so, explore different implementations.
As the algorithmic rules are separated from the  \OpenCL rules, these rules can explore valid implementations regardless of their concrete implementation in a concrete low-level programming model like \OpenCL.

\paragraph{Identity}
The identity rule in \autoref{eq:algo:identity} specifies that it is always valid to compose any function $f$ with the identity function \emph{id}.%
%
\begin{rerule}{lclcl}
  f & \rightarrow & f \circ \textit{id} & | & \textit{id} \circ f
  \label{eq:algo:identity}
\end{rerule}
%
The \textit{id} function can acts as a copy operation; this is, \eg, useful for expressing copies to local memory when composed with the \toLocal \OpenCL pattern: $\toLocal\ id$.

 
\paragraph{Iterate decomposition}
The rule in \autoref{eq:algo:iterate} expresses the fact that an iteration can be decomposed into several iterations.
%
\begin{rerule}{lcl}
  \iterateN\ (m+n)\ f
    & \rightarrow &
      \iterateN\ m\ f
        \circ \iterateN\ n\ f
  \label{eq:algo:iterate}
\end{rerule}

\paragraph{Reorder commutativity}
\autoref{eq:algo:reorder} shows that if the data can be reordered arbitrarily it does not matter if we apply a function $f$ to each element before or after the reordering.
%
\begin{rerule}{lcl}
  \map\ f \circ \reorder
    & \rightarrow & \reorder \circ \map\ f\\
  \reorder \circ \map\ f
    & \rightarrow & \map\ f \circ \reorder  
  \label{eq:algo:reorder}
\end{rerule}

\paragraph{Split-join}
The split-join rule in \autoref{eq:algo:splitjoin} partitions a map into two maps.
%
\begin{rerule}{lcl}
  \map\ f
    & \rightarrow &
      \join \circ \map\ (\map\ f) \circ \splitN\ n
  \label{eq:algo:splitjoin}
\end{rerule}
%
This allows us to nest map patterns in each other and, thus, \emph{maps} the computation to the thread hierarchy of the \OpenCL programming model, such as $\mapWorkgroup\ (\mapLocal\ f)$ as seen in our motivation example (\autoref{fig:codeex}).


\paragraph{Reduction}
We express the reduction function as a composition of other primitive functions, which is a fundamental aspect of our work.
From the algorithmic point of view we first define a partial reduction pattern \partRed.
This partial reduction reduces an array of $n$ elements to an array of $m$ elements where $1 \leq m < n$.
The reduction can be derived in a partial reduction combined with a full reduction as defined in \autoref{eq:algo:red}.
This definition ensures that we end up with one unique element.
% Another possible derivation consists in iterating a partial reduction until a full reduction is achieved (this is what $\infty$ represents).
%Note that our definition of \textit{reduce} remains correct since the result of a partial reduction is always composed with the reduction to ensure we end up with one unique element.
%
\begin{rerule}{lcl}
  \reduce\ f\ z
    & \rightarrow &
      \reduce\ f\ z \circ \partRed\ f\ z
  \label{eq:algo:red}
\end{rerule}

\paragraph{Partial Reduction}
\autoref{eq:algo:part-red} shows the rewrite rules for the partial reduction.
%
\begin{rerule}{lcl}
  \partRed\ f\ z
    & \rightarrow &
      \reduce\ f\ z\\
    & | &
      \partRed\ f\ z \circ \reorder\\    
    & | &
      \join \circ \map\ (\partRed\ f\ z) \circ \splitN\ n\\
    & | &
      \iterateN\ n\ (\partRed\ f\ z)
  \label{eq:algo:part-red}
\end{rerule}
%
The first possible derivation for partial reduction leads to the full reduction, \ie, $m=1$.
The next possible derivation expresses the fact that it is possible to reorder the elements to be reduced, expressing the commutativity property we demand in our definition of reduction (see \autoref{definition:pattern:reduce}).
The third derivation is actually the only place where parallelism is expressed in the definition of our reduction pattern.
This rule expressed the fact that it is valid to partition the input elements first and then reduce them independently.
Finally, the last possible derivation expresses the notion that it is possible to perform a partial reduction in an iterative process by repetitively applying the same partial reduction function.
This concept is very important when considering how the reduction function is typically implemented on \GPUs, as we saw in our discussion of the parallel reduction implementations shown in \autoref{lst:reduce0}--\ref{lst:reduce6}.


\paragraph{Simplification Rules}
\autoref{eq:algo:simpl} shows our simplification rules.
They express the fact that consecutive \splitN-\join pairs and \asVector-\asScalar pairs are equivalent to the identity.
%
\begin{rerule}{lcl}
  \join \circ \splitN\ n        & \rightarrow & \textit{id}\\
  %\splitN\ n \circ \join \circ\ f\ \circ \splitN\ n        & \rightarrow & \textit{id}\\
  \asScalar \circ \asVector\ n & \rightarrow & \textit{id}
  \label{eq:algo:simpl}
\end{rerule}

\paragraph{Fusion Rules}
Finally, our fusion rules are shown in \autoref{eq:algo:fusion}.
%
\begin{rerule}{lcl}
  \map\ f \circ \map\ g
    & \rightarrow & \map\ (f \circ g)\\
  \reduceSeq\ f\ z \circ \mapSeq\ g
    & \rightarrow & \\
  {\hspace{3em}}
  \reduceSeq\
    \big(\ \lambda\ (acc,x)\ .
      &\hspace{-.75em} f\ acc\ (g\ x)&\hspace{-.75em}\big)\ z
      % only reduce sequential is valid because non-associativity!!!
  \label{eq:algo:fusion}
\end{rerule}
%
The first rule fuses the functions applied by two consecutive maps.
The second rule fuses the map-reduce pattern by creating a lambda function that is the results of merging function $f$ and $g$ from the original reduction and map respectively.
This rule only applies to the sequential version since this is the only implementation not requiring the associativity property required by the more generic \reduce pattern.
% When generating code, these rules in effect allow us to fuse the implementation of the different functions and avoid having to store temporary results.
The functional programming community has studied more generic rules for fusion~\cite{CouttsLeSt2007,JonesToHo2001}.
However, as we currently focus on a restricted set of patterns our simpler fusion rules have, so far, proven to be sufficient.

\paragraph{Summary}
\autoref{fig:algoRules} given an overview of all algorithmic rules defined in this subsection.
Each single rule states a single statement of the relationship of multiple algorithmic patterns.
The rules allow us to formalize different algorithmic implementation strategies.
The rewrite rules regarding the \reduce pattern (\autoref{fig:algo:red}), for example, specify that an iterative implementation of the reduction as well as a divide-and-conquer style implementation are possible. 

The split-join rule (\autoref{fig:algo:splitjoin}) allows a divide-and-conquer style implementation of the \map pattern.
This eventually enables different parallel implementations, which we can express with \OpenCL, as we will see in the next subsection.

The rules presented here are by no means complete and can easily be extended to express more possible implementations.
When adding new patterns to the system this set of rules have to be extended as well.

In the next subsection we will discuss \OpenCL specific rewrite rules which allow us to map patter implementations to low-level \OpenCL concepts.

\newlength{\ruleSpace}
\setlength{\ruleSpace}{1em}
\begin{figure}[p]
\centering
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lclcl}
          f & \rightarrow & f \circ \textit{id} & | & \textit{id} \circ f
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Identity}
  \label{fig:algo:identity}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \iterateN\ (m+n)\ f
        & \rightarrow &
          \iterateN\ m\ f
            \circ \iterateN\ n\ f
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Iterate decomposition}
  \label{fig:algo:iterate}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \map\ f \circ \reorder
        & \rightarrow & \reorder \circ \map\ f\\
      \reorder \circ \map\ f
        & \rightarrow & \map\ f \circ \reorder\\  
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Reorder commutativity}
  \label{fig:algo:reorder}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \map\ f
        & \rightarrow &
          \join \circ \map\ (\map\ f) \circ \splitN\ n
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Split-join}
  \label{fig:algo:splitjoin}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \reduce\ f\ z
        & \rightarrow &
          \reduce\ f\ z \circ \partRed\ f\ z\\
      \partRed\ f\ z
        & \rightarrow &
          \reduce\ f\ z\\
        & | &
          \partRed\ f\ z \circ \reorder\\    
        & | &
          \join
            \circ \map\ (\partRed\ f\ z)
            \circ \splitN\ n\\
        & | &
          \iterateN\ n\ (\partRed\ f\ z)\\
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Reduction}
  \label{fig:algo:red}
\end{subfigure}


\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \splitN\ n \circ \join
            & \rightarrow & \textit{id}\\
      \asVector\ n \circ \asScalar
            & \rightarrow & \textit{id}\\
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Simplification rules}
  \label{fig:algo:simpl}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \map\ f \circ \map\ g
        & \rightarrow & \map\ (f \circ g)\\
      \reduceSeq\ f\ z \circ \mapSeq\ g
        & \rightarrow & \\
      {\hspace{3em}}
      \reduceSeq\
        \big(\ \lambda\ acc,x\ .
          &\hspace{-.75em} f\ acc\ (g\ x)&\hspace{-.75em}\big)\ z\\
          % only reduce sequential is valid because non-associativity!!!
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Fusion rules}
  \label{fig:algo:fusion}
\end{subfigure}

\caption{Overview of our algorithmic rewrite rules.}
\label{fig:algoRules}
\end{figure}





\subsection{OpenCL-Specific Rules}
\label{section:rules:opencl}

In this section we discuss our \OpenCL-specific rules that are used to apply \OpenCL optimizations and to lower high-level algorithmic concepts down to \OpenCL-specific ones.
The code generation process is described separately in the next section.

\paragraph{Maps}
The rule in \autoref{eq:low:map} is used to produce \OpenCL-specific map implementations that match the thread hierarchy of \OpenCL.
%
\begin{rerule}{lclcl}
  \map\ f
    & \rightarrow & \mapWorkgroup\ f\\
    & | & \mapLocal\ f\\
    & | & \mapGlobal\ f\\
    & | & \mapSeq\ f
  \label{eq:low:map}
\end{rerule}
%
Our implementation maintains context information to ensure the \OpenCL hierarchy is respected.
For instance, it is only legal to nest a \mapLocal inside a \mapWorkgroup and it is not valid to nest a \mapGlobal or another \mapWorkgroup inside a \mapWorkgroup.

\paragraph{Reduction}
There is only one rule for lowering to reduction to \OpenCL (\autoref{eq:low:red}), which expresses the fact that the only implementation known to the code generator is a sequential reduction.
Parallel implementations are defined at a higher level by composition of other algorithmic patterns.
Most existing high performance compilers treat the reduction directly as an irreducible primitive operation.
With our approach it is possible to explore different implementations for the reduction by simply applying different rules.
%
\begin{rerule}{lcl}
  \reduce\ f\ z & \rightarrow & \reduceSeq\ f\ z
  \label{eq:low:red}
\end{rerule}


\paragraph{Reorder}
\autoref{eq:low:stride} presents the rule that reorders elements of an array.
In our current implementation, we support two types of reordering:
no reordering, represented by the \textit{id} function, and \reorderStride, which reorders elements with a certain stride $s$.
As described earlier, the major use case for the stride reorder is to enable coalesced memory accesses.
%
\begin{rerule}{lcl}
  \reorder & \rightarrow & \reorderStride\ s\\
                & | & \textit{id}
  \label{eq:low:stride}
\end{rerule}
%
Other types of reordering functions could be implemented easily within this framework such as user-defined reorder function.

\paragraph{Local and Global Memory}
\autoref{eq:low:mem} shows two rules that enable \GPU local memory usage.
%
\begin{rerule}{lcl}
  \mapLocal\ f & \rightarrow & \toGlobal\ (\mapLocal\ f)\\
  \mapLocal\ f & \rightarrow & \toLocal\ (\mapLocal\ f)
  \label{eq:low:mem}
\end{rerule}
%
They express the fact that the result of a \mapLocal can always be stored in local memory or back in global memory.
This holds since a \mapLocal always exists within a \mapWorkgroup for which the local memory is defined in \OpenCL.
These rules allow us to determine how the data is mapped to the \GPU memory hierarchy.



\paragraph{Vectorization}
\autoref{eq:algo:vect} shows the vectorization rule.
%
\begin{rerule}{lcl}
  \map\ f
    & \rightarrow &
      \asScalar
        \circ \map\ (\vect\ n\ f)
        \circ \asVector\ n
  \label{eq:algo:vect}
\end{rerule}
%
Vectorization is achieved by using the \asVector and corresponding \asScalar patterns, which changes the element type of an array and adjust the length accordingly.
This rule is only allowed to be applied once to a given $\map\ f$ pattern.
This constrain can easily be checked by looking at the function's type, \ie, if it is a vector type, the rule cannot be applied.
% Another set of rules, not shown here for space reason, is used to propagate the \vect function recursively within $f$.
The \vect pattern is used to produce a vectorized version of the customizing function $f$.
Note that the vector width $n$ has to match for the vectorization of the function and the modification of the array.

\paragraph{Summary}
\autoref{fig:lowRules} show an overview of the \OpenCL-specific rewrite rules.
Each rule formalizes a different implementation or optimization strategy in \OpenCL.

The map rules (\autoref{fig:low:map}) describe the usage of the \OpenCL threading hierarchy with work-items and work-groups.

The reduce rule (\autoref{fig:low:red}) specifies the simple sequential implementation in \OpenCL, the parallel reduction is implemented in terms of other patterns as we saw in \autoref{section:rules:algo}.

The stride access rule (\autoref{fig:low:stride}) enables coalesced memory access, which are crucial for performance as we saw in \autoref{section:reduce:case-study}.

The local memory rule (\autoref{fig:low:mem}) allows the usage of the fast local memory.
We saw the benefits of using the local memory when evaluating the matrix multiplication expressed using the \allpairs pattern in \autoref{chapter:skelcl-evaluation}.

Finally, the vectorization rule (\autoref{fig:low:vect}) enables vectorization, which is a key optimization for the Intel \CPU architectures as we will see in \autoref{chapter:codeGeneration-evaluation}.

As for the algorithmic rules, the \OpenCL-specific rules presented here are not complete and do not cover all possible optimizations in \OpenCL.
Nevertheless, we will see in \autoref{chapter:codeGeneration-evaluation}, that these rules are a good starting set for generating efficient \OpenCL code.

\begin{figure}[t]
\centering
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lclcl}
      \map\ f
        & \rightarrow &
          \mapWorkgroup\ f & | & \mapLocal\ f\\
        & | &
          \mapGlobal\ f    & | & \mapSeq\ f\\
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Map}
  \label{fig:low:map}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \reduce\ f\ z
        & \rightarrow &
          \reduceSeq\ f\ z
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Reduction}
  \label{fig:low:red}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lclcl}
      \reorder
        & \rightarrow &
          \reorderStride\ s & | & \textit{id}
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Stride accesses or normal accesses}
  \label{fig:low:stride}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \mapLocal\ f
        & \rightarrow &
          \toGlobal\ (\mapLocal\ f)\\  
      \mapLocal\ f
        & \rightarrow & \toLocal\ (\mapLocal\ f)\\  
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Local/Global memory}
  \label{fig:low:mem}
\end{subfigure}

\vspace{\ruleSpace}
\begin{subfigure}[b]{1\linewidth}
  \begin{mdframed}
    \vspace{-\bigskipamount}
    \begin{rerule*}{lcl}
      \map\ f
        & \rightarrow &
          \asScalar
            \circ \map\ (\vect\ n\ f)
            \circ \asVector\ n
    \end{rerule*}
  \end{mdframed}
  \vspace{-1em}
  \caption{Vectorization}
  \label{fig:low:vect}
\end{subfigure}

\caption{Overview of the \OpenCL-specific rewrite rules.}
\label{fig:lowRules}
\end{figure}

\FloatBarrier


%\subsection{Automatic Rewriting Strategy}
%\label{sec:search}
%
%The rules presented in this section define a search space of possible implementations.
%In order to find the best possible low-level expression for a given target device, we have developed a simple automatic search strategy based loosely on Bandit-based optimization~\cite{demesmay09bandit}.
%Note that our current search strategy is just designed to prove that it is possible to find good implementations.
%We envision replacing this exploration strategy in the future by using machine-learning techniques to avoid having to search the space.
%However, this is orthogonal to the work presented in this paper.
%
%Our search strategy starts with the high-level expression and determines all the valid rules that can be applied at this stage.
%We use a Monte-Carlo method for evaluating the potential impact of each rule by randomly walking down the search tree.
%The rule that will lead to the best performance following the Monte-Carlo descent is chosen and applied to the expression.
%This process is repeated until we reach a terminal expression.
%Note that in addition to selecting the rules, we also search at the same time for the parameters controlling our patterns such as the vector size for the $\vect\ n$ pattern.
%Using this simple strategy, we found that less than a thousand expressions were evaluated to reach a solution in most cases.

\subsection{Applying the rewrite rules}
\label{sec:example}
In this section we will discuss some examples to show how the rewrite rules can be used to systematically rewrite applications expressed with the patterns introduced in \autoref{section:patterns}.
We will start by looking back at the first example from \autoref{section:code-generation:overview}.
Then we will look at the parallel reduction example and how we can systematically derive optimized implementations equivalent to the implementations discussed in \autoref{sec:reduce:case-study}.

\subsubsection{A First Example: Scaling a Vector}
\autoref{eq:vectorScal:impl} shows the implementation of the vector scaling example we used in \autoref{section:code-generation:overview}.
This directly corresponds to \autoref{fig:codeex:map}.
\begin{align}
  mul3\ x &= x \times 3\nonumber\\
  vectorScal &= \map\ mul3
  \label{eq:vectorScal:impl}
\end{align}
The application developer uses the algorithmic pattern \map together with the customizing function $mul3$ which multiplies every element with the number $3$.
\autoref{eq:vectorScal:rules} shows how this implementation can be systematically rewritten using the rewrite rules introduced in this section.
The numbers above the equal signs refer to \autoref{fig:algoRules} and \autoref{fig:lowRules} indicating which rule was used in the step.
\begin{align}
  &vectorScal = \map\ mul3\nonumber\\
  &\qquad\begin{aligned}
    &\overset{\ref{fig:algo:splitjoin}}{=\hspace{.2em}}
      \join \circ \map\ (\map\ mul3) \circ \splitN\ n_1\\
    &\overset{\ref{fig:low:vect}}{=\hspace{.2em}}
      \join \circ \map\ \big(\\
      &\qquad\quad \asScalar \circ \map\ (\vect\ n_2\ mul3) \circ \asVector\ n_2\\
      &\qquad\big) \circ \splitN\ n_1\\
    &\overset{\ref{fig:low:map}}{=\hspace{.2em}}
      \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \asScalar \circ \mapLocal\ (\\
      &\qquad\qquad\vect\ n_2\ mul3\\
      &\qquad\quad) \circ \asVector\ n_2\\
      &\qquad\big) \circ \splitN\ n_1
  \end{aligned}
  \label{eq:vectorScal:rules}
\end{align}
When selecting $n_1=1024$ and $n_2=4$ we obtain the expression shown in \autoref{fig:codeex:impl} from which \OpenCL code can be generated.
We will discuss the process of \OpenCL code generation in the next section.
But first we will discuss possible derivations for the parallel reduction.

\subsubsection{Systematic Deriving Implementations of Parallel Reduction}

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \iterateN\ (log_2\ wgSize)\ (\\
      &\qquad\qquad \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\quad)\\
      &\qquad \circ \join \circ \toLocal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad\big) \circ \splitN\ wgSize
  \end{aligned}
\end{align}
This is eq. to Listings 5.1--5.2.

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \iterateN\ (log_2\ wgSize)\ (\\
      &\qquad\qquad \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \reorderStride\ s\\
      &\qquad\quad)\\
      &\qquad \circ \join \circ \toLocal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad\big) \circ \splitN\ wgSize
  \end{aligned}
\end{align}
This is eq. to Listings 5.3.

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \iterateN\ (log_2\ wgSize)\ (\\
      &\qquad\qquad \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \reorderStride\ s\\
      &\qquad\quad)\\
      &\qquad \circ \join \circ \toLocal\ (\mapLocal\ (\reduceSeq\ (+)\ 0)) \circ \splitN\ 2\\
      &\qquad\big) \circ \splitN\ (2\times wgSize)
  \end{aligned}
\end{align}
This is eq. to Listing 5.4

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \join \circ \mapWarp\ (\\
      &\qquad\qquad\ \ \ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\quad) \circ \splitN\ 32\\
      &\qquad \circ \iterateN\ ((log_2\ wgSize) - (log_2\ 32))\ (\\
      &\qquad\qquad \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \reorderStride\ s\\
      &\qquad\quad)\\
      &\qquad \circ \join \circ \toLocal\ (\mapLocal\ (\reduceSeq\ (+)\ 0)) \circ \splitN\ 2\\
      &\qquad\big) \circ \splitN\ (2\times wgSize)
  \end{aligned}
\end{align}
This is eq. to Listing 5.5

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\quad \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \join \circ \mapWarp\ (\\
      &\qquad\qquad\ \ \ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\quad) \circ \splitN\ 32\\
      &\qquad \circ \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad \circ \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad \circ \join \circ \toLocal\ (\mapLocal\ (\reduceSeq\ (+)\ 0)) \circ \splitN\ 2\\
      &\qquad\big) \circ \splitN\ (2\times 128)
  \end{aligned}
\end{align}
This is eq. to Listing 5.6 (i.e. wgSize = 128)

\begin{align}
  &\hspace{-1.5em}vecSum = \reduce\ (+)\ 0\nonumber\\
  &\hspace{-2em}\quad\begin{aligned}
    &=\hspace{.2em}
      \reduce \circ \join \circ \mapWorkgroup\ \big(\\
      &\qquad\ \ \ \join \circ \toGlobal\ (\mapLocal\ (\mapSeq\ \id)) \circ \splitN\ 1\\
      &\qquad \circ \join \circ \mapWarp\ (\\
      &\qquad\qquad\ \ \ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\qquad \circ \join \circ \mapLane\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad\quad) \circ \splitN\ 32\\
      &\qquad \circ \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad \circ \join \circ \mapLocal\ (\reduceSeq\ (+)\ 0) \circ \splitN\ 2\\
      &\qquad \circ \join\\
      &\qquad\quad \circ\toLocal\ (\mapLocal\ (\reduceSeq\ (+)\ 0))\\
      &\qquad \circ \splitN\ (blockSize/wgSize) \circ \reorderStride\ s\\
      &\qquad\big) \circ \splitN\ blockSize
  \end{aligned}
\end{align}
This is eq. to Listing 5.7

\paragraph{Example: Deriving a Fused Implementation}

\begin{figure*}[t]
\begin{align*}
  &\text{\textit{asum}} = \reduce\ (+)\ 0\ \circ\ \map\ abs\\[.5em]
  %
  &\begin{aligned}
  & \overset{\ref{fig:algo:red}}{\hspace{.2em}=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\partRed\ (+)\ 0)\ \circ\ \splitN\ n\\
        &\circ\ \map\ abs
      \end{aligned}\\[.5em]
  %
  & \overset{\ref{fig:algo:splitjoin}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\partRed\ (+)\ 0)\ \circ\ \splitN\ n\\
        &\circ\ \join\ \circ\ \map\ (\map\ abs)\ \circ\ \splitN\ n
      \end{aligned}\\[.5em]
  %
  & \overset{\ref{fig:algo:simpl}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\partRed\ (+)\ 0)\\
        &\circ\ \map\ (\map\ abs)\ \circ\ \splitN\ n
      \end{aligned}\\[.5em]
  %
  & \overset{\ref{fig:algo:fusion}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\partRed\ (+)\ 0\ \circ\ \map\ abs)\\
        &\circ\ \splitN\ n
      \end{aligned}\\[.5em]
  %
  & \overset{\ref{fig:low:map}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\partRed\ (+)\ 0\ \circ\ \mapSeq\ abs)\\
        &\circ\ \splitN\ n
      \end{aligned}\\[.5em]
  %
  & \overset{\hspace{-1.3em}\ref{fig:algo:red}\& \ref{fig:low:red}\hspace{-1.1em}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\ \circ\ \map\ (\reduceSeq\ (+)\ 0\ \circ\ \mapSeq\ abs)\\
        &\circ\ \splitN\ n
      \end{aligned}\\[.5em]
  %
  & \overset{\ref{fig:algo:fusion}}{=\hspace{.2em}}
      \begin{aligned}
        & \reduce\ (+)\ 0\\
        &\circ\ \join\\
        &\circ\ \map\ \big(\reduceSeq\ (\lambda\ a, b\ .\ a+(abs\ b))\ 0\big)\\
        &\circ\ \splitN\ n
      \end{aligned}
  \end{aligned}
\end{align*}
\caption{Derivation for \emph{asum}$(\vec{x})$ to a fused parallel version.
  The numbers above the equality sign refer to the rules from sections ....
}
\label{fig:derivation}
\end{figure*}




To achieve good performance it is in general beneficial to avoid storing intermediate results.
Rule~\ref{fig:algo:fusion} allows us to apply this principle and fuse two patterns into one, thus, avoiding intermediate results.
Figure~\ref{fig:derivation} shows how we can derive a fused version for calculating the sum of absolute value, \emph{asum}, from the high-level expression written by the programmer.
We write the derivation as a sequence of equations using a slightly more mathematical notation.
The numbers above the equality sign refer to the rules applied.

We start by applying the reduction rule~\ref{fig:algo:red} twice:
first to replace \reduce with \reduce~$\circ$~\partRed and then a second time to expand \partRed.
To get (2) we expand \map, which can be simplified by removing the two corresponding \join and \splitN patterns.
In the step from (3) to (4) two \map patterns are fused and in the next step the nested \map is lowered into the \mapSeq pattern to obtain (5).
By first transforming \partRed back into \reduce (using rule~\ref{fig:algo:red}) and then applying the lowering rule~\ref{fig:low:red} we get (6).
Finally, we apply rule~\ref{fig:algo:fusion} to fuse the \mapSeq and \reduceSeq into a single \reduceSeq.
This sequence of transformations results in expression (7), which allows for a more optimal implementation since no temporary storage is required for the intermediate result.



\FloatBarrier



\subsection{Summary}

The power of our approach lies in the composition of our rules that produce complex low-level expressions from simple high-level expressions.
Looking back at our example in Figure~\ref{fig:codeex}, we see how a simple algorithmic pattern can effectively be derived into a low-level expression by applying the rules.
This expression matches hardware concepts expressible with \OpenCL such as mapping computation and data to the thread and memory hierarchy. % and vectorization.
Each single rule encodes a simple, easy to understand, provable fact.
By composition of the rules we systematically derive low-level expressions which are semantically equivalent to the high-level expressions by construction.
This results in a powerful mechanism to safely explore the space of possible implementations.
% Using these rules and our automatic search technique we now have a powerful mechanism to explore the space of possible program implementations.


