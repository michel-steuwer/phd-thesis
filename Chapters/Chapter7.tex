% Chapter 7: Patterns for a greater good

\chapter[Towards a Holistic, Structured Approach for\\ Programming and Optimizing Programs]{Towards a Holistic, Structured Approach for Programming and Optimizing Programs}
\chaptermark{Towards a Holistic, Structured Programming Approach}

\label{ch:seventh} % For referencing the chapter elsewhere, use \autoref{ch:name}

The previous technical chapters have addresses the two main challenges we identified at the beginning: programmability and performance portability.
In this chapter we will summarize SkelCL the high-level programming model introduced in \autoref{part:skelcl} which addresses the programmability challenge and the novel pattern-based code generation technique introduced in \autoref{part:codeGeneration} which addresses the performance portability challenge.
We will especially refer back to the four main contributions of this thesis as stated in \autoref{ch:introduction}.
Furthermore, we will describe how the two presented projects relate to each other and how they can be combined in the future for creating a holistic structured approach for programming and optimizing programs offering SkelCL's high-level abstractions and integration in \Cpp together with the high and portable performance provided by our code generator technique.

\section{Addressing the Programmability Challenge}

In \autoref{part:skelcl} of this thesis we introduced SkelCL which addresses the programmability challenge of modern parallel processors.

\paragraph{The SkelCL programming model}
In \autoref{chapter:skelcl} we used a case study to show the drawbacks of programming with the state-of-the-art low-level programming approach OpenCL.
The SkelCL programming model provides three high-level features which help to overcome these drawbacks, raise the level of abstraction for the programmer and, thus, simplify parallel programming:
\begin{itemize}
  \item parallel container data types (explained in detail in \autoref{section:skelcl-programming-model:container}) automatically perform the low-level memory management and make their data transparently accessible to both \CPU and \GPUs;
  \item algorithmic skeletons (explained in detail in \autoref{section:skelcl-programming-model:skeletons}) are used for easily expressing parallel programs in a structured, high-level manner;
  \item data distribution and redistribution (explained in detail in \autoref{section:skelcl-programming-model:distribution}) greatly simplify programming of multi-GPU systems by transparently performing all necessary data transfers.
\end{itemize}

\noindent
The SkelCL programming model is implemented as a \Cpp library (explained in detail in \autoref{section:skelcl-library}) deeply integrated with features from the latest \Cpp standard.

In \autoref{chapter:skelcl-evaluation} we showed that the SkelCL programming model and its implementation as a \Cpp library are suitable for implementing real-world applications from a broad range of domains.
For all investigated examples we showed that the programming is greatly simplified with shorter and easier to understand code.
The SkelCL library offers competitive performance to manually written OpenCL code on single- and multi-GPU systems on single- and multi-GPU systems for all but two benchmarks.
For these two benchmarks (\emph{dot product} and \emph{asum}) multiple OpenCL kernels are executed instead of a single fused one.
The code generation technique presented in \autoref{part:codeGeneration} overcomes this drawback of SkelCL.

\bigskip
The SkelCL programming model and its implementation is the first major contribution of this thesis.

\paragraph{Algorithmic Skeletons for Stencil and Allpairs}
Alongside SkelCL we introduced two novel algorithmic skeletons.
The \emph{stencil} skeleton (explained in detail in \autoref{section:stencil:skeleton}) simplifies stencil computations common in domains like image processing.
The \emph{allpairs} skeleton (explained in detail in \autoref{sec:allpairs_skeleton}) allows to easily express allpairs computations like matrix multiplication.
We formally define both skeleton and provide efficient single- and multi-\GPU implementations.
For the allpairs skeleton we identified an optimization rule, which enables an optimized implementation especially beneficial on modern \GPUs.

The evaluation for matrix multiplication (\autoref{section:skelcl:matrixMult}) show the competitive performance of the provided implementation of the allpairs skeleton compared to highly tuned library code.
We discussed performance results for the implementations of the stencil skeleton for image processing applications in \autoref{sec:imageProcessing} and a physics simulation in \autoref{sec:physicsSim}.
These results show that the same performance is achieved as compared with manually tuned low-level OpenCL code.
For both skeletons the evaluation shows that programming is greatly simplified and not only the boilerplate management code is avoided but \GPU specific optimizations, like the usage of local memory, are hidden from the user.

\bigskip
The formal definitions and efficient \GPU implementations of the two novel algorithmic skeletons is the second major contribution of this thesis.


\section{Addressing the Performance Portability Challenge}
In \autoref{part:codeGeneration} of this thesis we introduced a novel code generation technique which addresses the performance portability challenge.

\paragraph{A Formal System for Rewriting Pattern-Based Programs}
We started \autoref{chapter:codeGeneration} with an investigation into the portability of optimization using the low-level programming approach OpenCL and showed, that performance and optimizations in OpenCL are not portable.
In the following we introduced a set of high-level and low-level patterns (explained in detail in \autoref{section:patterns}) together with provably correct rewrite rules (explained in detail in \autoref{section:rules}).
While the high-level patterns capture algorithmic concepts, very similar to the algorithmic skeletons used in SkelCL, the low-level patterns are different, as each low-level pattern models a specific feature of the target low-level programming model OpenCL.
The rewrite rules encode high-level algorithmic as well low-level optimizations which can be systematically applied to a pattern-based program.
The rewrite rules especially explain how the high-level algorithmic concepts can be mapped to OpenCL, the target low-level programming model.

We show the soundness of the system by giving formal definitions of the semantics and types of each pattern and proving for each rewrite rule that it not changes the semantic of the rewritten expression.
In \autoref{sec:applying:rules} we showed how the rewrite rules can be systematically applied for deriving different, hardware-specific low-level expressions from a single high-level representation.

\bigskip
This formal foundation makes our rewrite approach suitable for automation of optimizing code in a compiler and is the third major contribution of this thesis.

\paragraph{A Code Generator Offering Performance Portability}\hfill\\
Based on the formal foundations we developed and presented the design and implementation of a code generator (explained in detail in \autoref{section:opencl:code:generator}) which generates highly efficient, hardware-specific OpenCL code from a single pattern-based expression.
The single high-level representation is transformed into a hardware-specific low-level representation using the rewrite rules, as shown in \autoref{sec:applying:rules}.
The low-level representation is then compiled to highly efficient OpenCL code.
Our implementation employs a powerful type system to encode information about the size of arrays used for doing static memory allocation.
We use type inference for inferring most types automatically and releasing the programmer from specifying types explicitly.

Our performance evaluation in \autoref{chapter:codeGeneration-evaluation} shows, that using this novel approach OpenCL code is generated which performs comparable to manually optimized library codes on three different parallel processors.
This novel code generation approach offers true performance portability, since hardware-specific code is systematically generated from a single, portable high-level representation.

\bigskip
This code generator offering true performance portability is the fourth, and final, major contribution of this thesis.


\section[Future Work]{Future Work:\\ Towards a Holistic, Structured Approach for Programming and Optimizing Programs}
\label{section:future-work}
The two separate projects described in this thesis can naturally be combined in the future to obtain a single holistic approach which offers the advantages of both:
the high-level abstractions from SkelCL which structure and simplify parallel programming as well as the highly optimized and portable performance delivered systematically by our novel code generation technique.

This combination makes sense as both projects use structured parallel programming in the form of parallel patterns (or algorithmic skeletons as they are called in SkelCL) as their fundamental building block.
In SkelCL the patterns are used by the programmer to describe the algorithmic structure of the program.
In the code generator rewrite rules transform programs expressed with patterns into a low-level form from which efficient OpenCL code is generated.

As shown in \autoref{part:skelcl} the SkelCL programming model provides a great programming interface successfully hiding complicated details of parallelism and the underlying hardware from the programmer.
But the current implementation as a \Cpp library has some restrictions in certain areas, even somewhat limiting the expressiveness of the programming model.
For example, is the nesting of patterns not supported as it is complicated to support in a library implementation.
Furthermore, when evaluating SkelCL in \autoref{chapter:skelcl-evaluation} we identified a performance problem for two benchmarks because the current SkelCL library implementation does generate a separate OpenCL kernel for each pattern instead of generating a single fused kernel.
The current library is optimized towards and tested on \GPUs by Nvidia and does not necessary offer the same level of performance on other hardware platforms.

As shown in \autoref{part:codeGeneration} our code generator addresses all these performance drawbacks of the SkelCL library implementation systematically generating highly efficient code on three hardware platforms.
But currently the high-level and low-level patterns are not well integrated in a programming language like the SkelCL library is integrated in \Cpp.
This makes is currently restricts the expressiveness and makes it difficult to implement complex real-world applications like the LM OSEM expressed in SkelCL.

A future holistic approach will avoid all of these drawbacks by using SkelCL as the \emph{frontend} offering its convenient programming interface integrated with a programming language to the user combined with the code generator as the \emph{backend} systematically compiling the pattern-based expression into hardware-specific code.

\bigskip
In the following we will discuss possible future enhancements to SkelCL as well as the code generator.

\subsection{Enhancing the SkelCL Programming Model}
\label{section:future-work:skelcl}

In this section we are going to explore possible enhancements to the SkelCL programing model as well as discuss current limitations of the \Cpp library implementation and how those could be liftet in the future.
We will start with the Stencil skeleton and how its implementation could be enhanced to improve its usability.
We will then discuss possible enhancements to lift limitations regarding composing and nesting of SkelCL's skeletons and container data types.
Next we will discuss the possibility to extend SkelCL by supporting more algorithmic skeletons especially task-parallel skeletons for enhancing its expressiveness.
Finally, we will discuss how SkelCL could be extended for supporting truly heterogeneous execution where different types of parallel processors, \eg, \CPU and \GPU, are used efficiently together.

\paragraph{Enhancing the Stencil Skeleton}
In SkelCL we introduced a new algorithmic skeleton for Stencil computations (\autoref{section:stencil:skeleton}).
In \autoref{sec:skelcl:stencil} we discussed two implementations \code{MapOverlap} and \code{Stencil}.
Each implementation has its advantages and disadvantages regarding usability, expressiveness, and performance.

To improve the usability, the shape of the stencil would be inferred automatically from the customizing function instead of require the user to provide this information explicitly as it is currently the case.

To improve the expressiveness, more options for performing boundary handling could be added allowing additional application to be easily expressed with the skeleton.
Furthermore, many simulations could be expressed with the stencil skeleton if application-specific functions would be allowed for checking a terminating condition when performing stencil computations iteratively.

To improve the performance, the decision which implementation, \code{MapOverlap} or \code{Stencil}, to use in which situation could be taken automatically by the SkelCL implementation.
A performance model predicting the runtime of each implementation in a certain situation could be build reflecting the performance characteristics of both implementations.
Based on this model the runtime system could easily select the appropriate implementation for a given use of the stencil skeleton.

\bigskip
The described enhancements are representative for similar possible enhancements throughout the current SkelCL library implementation.
Overall these type of enhancements have only minor effects on the main features of SkelCL instead they refine the current SkelCL implementation.

\paragraph{Allow Nesting of Skeletons and Container Data Types}
Due to its current implementation the nesting of skeletons is not allowed in SkelCL, therefore, it is not possible to express nested parallelism easily.
Similarly, it is not possible to nest container data types in each other.
SkelCL provides a special two dimensional data type but there is no generic mechanism for building higher dimensional data types.

Both drawbacks are limitations given by the current library implementation.
A skeleton is directly translated into an OpenCL kernel preventing the nesting of skeletons.
The container implementation assumes a flat representation of the data in memory, which is not necessary the case when nesting containers.

By empowering SkelCL's implementation with our code generation technique we can overcome both drawbacks in the future.
Nesting of computations expressed as skeletons as well as data in the form of arrays is fully supported by our current code generator.
By integrating this implementation in SkelCL nested parallelism can be exploited where OpenCL kernels and matching appropriate data representations are generated automatically.

\paragraph{Adding Support for Task-Parallel Skeletons}
SkelCL currently focuses on data-parallel skeletons as they match the performance characteristics of modern \GPU systems.
Nevertheless could it be useful to explore the introduction of task-parallel skeletons to SkelCL.
The well-known pipeline skeleton could, for example, be useful for systematically optimizing the data transfer to and from \GPUs by overlapping computation and communication.
The pipeline skeleton could also be used in a multi-\GPU setting where each \GPUs performs a different stage of the pipeline.
Similarly, a task farm skeleton could be used to schedule different possibly data-parallel computations across multiple \GPUs.

\paragraph{Adding Support for True Heterogeneous Execution}\hfill\\
SkelCL uses OpenCL for its implementation, therefore, it is possible to use SkelCL not only for programming \GPUs but also other types of accelerators and multi-core \CPUs.
As we showed in \autoref{part:codeGeneration} the performance of OpenCL is not portable across these broad range of parallel processors.
Therefore, the current implementation of SkelCL would presumably not perform particular well on other types of parallel processors supported by OpenCL.
Furthermore, in a system comprising multiple OpenCL devices when distribution the data across these devices SkelCL currently assumes that all devices will roughly process the data in an equal amount of time, \ie, SkelCL's block distribution divides the input data into equally sized chunks each processed by a different OpenCL device.
This assumption works well for homogeneous multi-\GPU systems as used in this thesis, but breaks down for truly heterogeneous execution where multiple parallel processors of different types are used together.

The code generation technique presented in \autoref{part:codeGeneration} will address the first drawback and generate efficient and performance portable code for each single OpenCL device.
More research has to be conducted for performing efficient executions on heterogeneous systems.
The structured manner in which programs are expressed with SkelCL could help to address this issue, as researchers have already build performance models for structured programming~\cite{BischofGK03,Alt2007,JavedL11,StegmeierFrJAUn2015} predicting runtime performance.
Such models could be used for minimizing the overall runtime by most efficiently using all available hardware resources.


\subsection{Enhancing the Pattern-Based Code Generator}
\label{section:future-work:codeGenerator}

This section discusses possible enhancements to our novel pattern-based code generator. 
Firstly, we discuss how the proposed rewrite rules can be efficiently applied automatically and how this will enable compilers to perform the advanced optimizations discussed throughout the thesis autonomously without any user interaction.
We will then describe possible enhancements to the current OpenCL backend, before we explore the possibility to add additional backends producing efficient code in other low-level programming system, \eg, OpenMP or MPI.
Finally, we will discuss how the current system can easily be extended with additional high-level patterns and rewrite rules.

\paragraph{Automatically Applying of the Rewrite Rules}
The formalism and implementation described in this thesis 
We already discussed this important issue in 

\paragraph{Enhance the Current OpenCL Backend}
% More advanced vectorization
% Enhance memory management - private and constant memory, reuse memory (graph coloring)

\paragraph{Adding Additional Backends}

\paragraph{Adding Additional High-Level Patterns and Rewrite Rules}

